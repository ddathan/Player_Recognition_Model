{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player & Team Recognition Assignment\n",
    "\n",
    "Dom Dathan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# image handling\n",
    "from PIL import Image\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Classes that will be used:\n",
    "\n",
    "PlayerTilesDataset is a dataset class for the images to be loaded into the model easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerTilesDataset(Dataset):\n",
    "    \"\"\"Image Loader dataset for player tiles.\"\"\"\n",
    "    def __init__(self, dirname, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (string): Path to the images organized in a team\\player\\image.jpg format.\n",
    "            transform: Any Pytorch transform to be applied\n",
    "        \"\"\"\n",
    "        \n",
    "        # initalise image paths\n",
    "        self.image_paths = []\n",
    "        \n",
    "        # initialse image labels - one for team and one for player\n",
    "        self.labels1 = []\n",
    "        self.labels2 = []\n",
    "        \n",
    "        # get all team folders\n",
    "        teams = [f.name for f in os.scandir(dirname) if f.is_dir()]\n",
    "\n",
    "        # iterate over each team folder\n",
    "        for team in list(teams):\n",
    "\n",
    "            # create team directory\n",
    "            teams_dir = os.path.join(dirname,team)\n",
    "\n",
    "            # get all players for that team\n",
    "            players = [f.name for f in os.scandir(teams_dir) if f.is_dir()]\n",
    "\n",
    "            # iterate over each player\n",
    "            for player in list(players):\n",
    "\n",
    "                # create player directory\n",
    "                player_dir = os.path.join(dirname,team,player)\n",
    "\n",
    "                # get all images for that player\n",
    "                images = [f.name for f in os.scandir(player_dir)]\n",
    "\n",
    "                # iterate over all images\n",
    "                for image in images:\n",
    "\n",
    "                    # append image path\n",
    "                    self.image_paths.append(os.path.join(dirname,team,player,image))\n",
    "                    \n",
    "                    # append labels\n",
    "                    self.labels1.append(team)\n",
    "                    self.labels2.append(team+'_'+player)\n",
    "\n",
    "        # Create a dictionary mapping each label to a index from 0 to len(classes) for both outputs\n",
    "        self.label1_to_idx = {x:i for i,x in enumerate(set(self.labels1))}\n",
    "        self.label2_to_idx = {x:i for i,x in enumerate(set(self.labels2))}\n",
    "        \n",
    "        # Create a dictionary mapping each index to corresponding label for both outputs\n",
    "        self.idx_to_label1 = {ind: label for label, ind in self.label1_to_idx.items()}\n",
    "        self.idx_to_label2 = {ind: label for label, ind in self.label2_to_idx.items()}\n",
    "        \n",
    "        # transform if requessted\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return length of dataset\n",
    "        return len(self.image_paths)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        # open and send one image and label\n",
    "        \n",
    "        # get image path\n",
    "        img_name = self.image_paths[idx]\n",
    "        \n",
    "        # get image labels\n",
    "        label1 = self.labels1[idx] # team\n",
    "        label2 = self.labels2[idx] # player\n",
    "        \n",
    "        # open image\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # transform if requested\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image,self.label1_to_idx[label1],self.label2_to_idx[label2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net class is a class for the neural network\n",
    "Since this is an image prediction problem a CNN is chosen\n",
    "The modeule returns two outputs - one for the team prediction and one for the person prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"Pytorch neural network model class\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 84)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 6)\n",
    "        self.fc4 = nn.Linear(84,54)\n",
    "        self.drop_layer = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.drop_layer(x)\n",
    "        #print(x.size())\n",
    "        x = x.view(-1,16 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x1 = self.fc3(x)\n",
    "        x2 = self.fc4(x)\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory of folder holding all images\n",
    "imdir = 'part1'\n",
    "\n",
    "# transform images to tensor\n",
    "t = transforms.ToTensor()\n",
    "\n",
    "# load dataset\n",
    "train_dataset = PlayerTilesDataset(dirname=imdir,transform=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set targets\n",
    "targets = [team + '_' + player for team, player in zip(train_dataset.labels1, train_dataset.labels2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in each class of WHOLE dataset:\n",
      "nottingham_forrest_nottingham_forrest_person_7 : 123, 4.7%\n",
      "bristol_bristol_person_25 : 142, 5.4%\n",
      "wigan_wigan_person_20 : 58, 2.2%\n",
      "bristol_bristol_person_19 : 41, 1.6%\n",
      "nottingham_forrest_nottingham_forrest_person_3 : 11, 0.4%\n",
      "bristol_bristol_person_23 : 113, 4.3%\n",
      "spal_team_a_spal_team_a_person_19 : 64, 2.4%\n",
      "bristol_bristol_person_8 : 175, 6.6%\n",
      "nottingham_forrest_nottingham_forrest_person_18 : 9, 0.3%\n",
      "nottingham_forrest_nottingham_forrest_person_22 : 62, 2.4%\n",
      "bristol_bristol_person_2 : 17, 0.6%\n",
      "bristol_bristol_person_45 : 82, 3.1%\n",
      "bristol_bristol_person_40 : 133, 5.0%\n",
      "wigan_wigan_person_19 : 58, 2.2%\n",
      "bristol_bristol_person_31 : 28, 1.1%\n",
      "spal_team_a_spal_team_a_person_6 : 4, 0.2%\n",
      "spal_team_a_spal_team_a_person_10 : 9, 0.3%\n",
      "bristol_bristol_person_4 : 69, 2.6%\n",
      "spal_team_b_spal_team_b_person_29 : 4, 0.2%\n",
      "spal_team_a_spal_team_a_person_17 : 31, 1.2%\n",
      "wigan_wigan_person_4 : 7, 0.3%\n",
      "middlesbrough_middlesbrough_person_17 : 24, 0.9%\n",
      "middlesbrough_middlesbrough_person_6 : 97, 3.7%\n",
      "bristol_bristol_person_6 : 73, 2.8%\n",
      "middlesbrough_middlesbrough_person_8 : 77, 2.9%\n",
      "spal_team_b_spal_team_b_person_23 : 9, 0.3%\n",
      "spal_team_a_spal_team_a_person_15 : 29, 1.1%\n",
      "nottingham_forrest_nottingham_forrest_person_19 : 32, 1.2%\n",
      "bristol_bristol_person_5 : 87, 3.3%\n",
      "wigan_wigan_person_3 : 29, 1.1%\n",
      "spal_team_b_spal_team_b_person_37 : 47, 1.8%\n",
      "spal_team_b_spal_team_b_person_10 : 6, 0.2%\n",
      "bristol_bristol_person_14 : 161, 6.1%\n",
      "bristol_bristol_person_11 : 95, 3.6%\n",
      "middlesbrough_middlesbrough_person_26 : 4, 0.2%\n",
      "nottingham_forrest_nottingham_forrest_person_8 : 23, 0.9%\n",
      "wigan_wigan_person_15 : 6, 0.2%\n",
      "bristol_bristol_person_32 : 29, 1.1%\n",
      "middlesbrough_middlesbrough_person_5 : 39, 1.5%\n",
      "middlesbrough_middlesbrough_person_2 : 18, 0.7%\n",
      "bristol_bristol_person_9 : 20, 0.8%\n",
      "wigan_wigan_person_9 : 60, 2.3%\n",
      "middlesbrough_middlesbrough_person_27 : 50, 1.9%\n",
      "nottingham_forrest_nottingham_forrest_person_28 : 43, 1.6%\n",
      "wigan_wigan_person_5 : 63, 2.4%\n",
      "bristol_bristol_person_29 : 60, 2.3%\n",
      "nottingham_forrest_nottingham_forrest_person_11 : 9, 0.3%\n",
      "wigan_wigan_person_11 : 2, 0.1%\n",
      "spal_team_a_spal_team_a_person_77 : 22, 0.8%\n",
      "nottingham_forrest_nottingham_forrest_person_23 : 72, 2.7%\n",
      "middlesbrough_middlesbrough_person_11 : 10, 0.4%\n",
      "wigan_wigan_person_21 : 33, 1.3%\n",
      "wigan_wigan_person_22 : 15, 0.6%\n",
      "bristol_bristol_person_42 : 52, 2.0%\n"
     ]
    }
   ],
   "source": [
    "def get_target_counts(targets):\n",
    "    # count instances of each class in targets\n",
    "    return {target_class: targets.count(target_class) for target_class in set(targets)}\n",
    "\n",
    "\n",
    "def print_target_counts(targets):\n",
    "    target_counts = get_target_counts(targets)\n",
    "    total_targets = 0\n",
    "    for target in target_counts:\n",
    "        total_targets += target_counts[target]\n",
    "    for target in target_counts:\n",
    "        print('{} : {}, {:.1f}%'.format(target,target_counts[target],100*target_counts[target]/total_targets))\n",
    "\n",
    "print('Number of instances in each class of WHOLE dataset:')\n",
    "print_target_counts(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train 70%, validation 20% and test 10%\n",
    "# Use stratify to ensure equal weighting of each class\n",
    "# First split into train and the rest\n",
    "train_idx, rest_idx = train_test_split(np.arange(len(targets)),test_size=0.3, random_state=42, \n",
    "                                        shuffle=True, stratify=targets)\n",
    "# set train targets and assign the targets of the remaining samples\n",
    "train_targets = [targets[i] for i in train_idx]\n",
    "rest_targets = [targets[i] for i in rest_idx]\n",
    "\n",
    "# next split rest into validation and test\n",
    "valid_idx, test_idx = train_test_split(np.arange(len(rest_targets)),test_size=0.33, random_state=42, \n",
    "                                        shuffle=True)\n",
    "\n",
    "# refer valid_idx and test_idx back to rest_idx\n",
    "valid_idx = rest_idx[valid_idx]\n",
    "test_idx = rest_idx[test_idx]\n",
    "\n",
    "# set validation and test target values\n",
    "valid_targets = [targets[i] for i in valid_idx]\n",
    "test_targets = [targets[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  1845\n",
      "Number of validation samples:  529\n",
      "Number of test samples:  262\n",
      "Number of instances in each class of TRAIN dataset:\n",
      "nottingham_forrest_nottingham_forrest_person_7 : 86, 4.7%\n",
      "bristol_bristol_person_25 : 99, 5.4%\n",
      "wigan_wigan_person_20 : 41, 2.2%\n",
      "bristol_bristol_person_19 : 29, 1.6%\n",
      "nottingham_forrest_nottingham_forrest_person_3 : 8, 0.4%\n",
      "bristol_bristol_person_23 : 79, 4.3%\n",
      "spal_team_a_spal_team_a_person_19 : 45, 2.4%\n",
      "bristol_bristol_person_8 : 123, 6.7%\n",
      "nottingham_forrest_nottingham_forrest_person_22 : 43, 2.3%\n",
      "nottingham_forrest_nottingham_forrest_person_18 : 6, 0.3%\n",
      "bristol_bristol_person_2 : 12, 0.7%\n",
      "bristol_bristol_person_45 : 57, 3.1%\n",
      "bristol_bristol_person_40 : 93, 5.0%\n",
      "wigan_wigan_person_19 : 41, 2.2%\n",
      "bristol_bristol_person_31 : 20, 1.1%\n",
      "spal_team_a_spal_team_a_person_6 : 3, 0.2%\n",
      "spal_team_a_spal_team_a_person_10 : 6, 0.3%\n",
      "bristol_bristol_person_4 : 48, 2.6%\n",
      "spal_team_b_spal_team_b_person_29 : 3, 0.2%\n",
      "spal_team_a_spal_team_a_person_17 : 22, 1.2%\n",
      "wigan_wigan_person_4 : 5, 0.3%\n",
      "middlesbrough_middlesbrough_person_17 : 17, 0.9%\n",
      "middlesbrough_middlesbrough_person_6 : 68, 3.7%\n",
      "middlesbrough_middlesbrough_person_8 : 54, 2.9%\n",
      "bristol_bristol_person_6 : 51, 2.8%\n",
      "spal_team_b_spal_team_b_person_23 : 6, 0.3%\n",
      "spal_team_a_spal_team_a_person_15 : 20, 1.1%\n",
      "nottingham_forrest_nottingham_forrest_person_19 : 22, 1.2%\n",
      "wigan_wigan_person_3 : 20, 1.1%\n",
      "bristol_bristol_person_5 : 61, 3.3%\n",
      "spal_team_b_spal_team_b_person_37 : 33, 1.8%\n",
      "spal_team_b_spal_team_b_person_10 : 4, 0.2%\n",
      "bristol_bristol_person_14 : 113, 6.1%\n",
      "bristol_bristol_person_11 : 67, 3.6%\n",
      "middlesbrough_middlesbrough_person_26 : 3, 0.2%\n",
      "nottingham_forrest_nottingham_forrest_person_8 : 16, 0.9%\n",
      "wigan_wigan_person_15 : 4, 0.2%\n",
      "bristol_bristol_person_32 : 20, 1.1%\n",
      "middlesbrough_middlesbrough_person_5 : 27, 1.5%\n",
      "middlesbrough_middlesbrough_person_2 : 13, 0.7%\n",
      "bristol_bristol_person_9 : 14, 0.8%\n",
      "wigan_wigan_person_9 : 42, 2.3%\n",
      "nottingham_forrest_nottingham_forrest_person_28 : 30, 1.6%\n",
      "middlesbrough_middlesbrough_person_27 : 35, 1.9%\n",
      "wigan_wigan_person_5 : 44, 2.4%\n",
      "bristol_bristol_person_29 : 42, 2.3%\n",
      "nottingham_forrest_nottingham_forrest_person_11 : 6, 0.3%\n",
      "wigan_wigan_person_11 : 2, 0.1%\n",
      "spal_team_a_spal_team_a_person_77 : 15, 0.8%\n",
      "nottingham_forrest_nottingham_forrest_person_23 : 50, 2.7%\n",
      "middlesbrough_middlesbrough_person_11 : 7, 0.4%\n",
      "wigan_wigan_person_21 : 23, 1.2%\n",
      "wigan_wigan_person_22 : 11, 0.6%\n",
      "bristol_bristol_person_42 : 36, 2.0%\n",
      "\n",
      "\n",
      "Number of instances in each class of VALID dataset:\n",
      "nottingham_forrest_nottingham_forrest_person_7 : 24, 4.5%\n",
      "bristol_bristol_person_25 : 22, 4.2%\n",
      "wigan_wigan_person_20 : 11, 2.1%\n",
      "bristol_bristol_person_19 : 5, 0.9%\n",
      "nottingham_forrest_nottingham_forrest_person_3 : 3, 0.6%\n",
      "bristol_bristol_person_23 : 21, 4.0%\n",
      "spal_team_a_spal_team_a_person_19 : 18, 3.4%\n",
      "bristol_bristol_person_8 : 37, 7.0%\n",
      "nottingham_forrest_nottingham_forrest_person_22 : 14, 2.6%\n",
      "nottingham_forrest_nottingham_forrest_person_18 : 2, 0.4%\n",
      "bristol_bristol_person_2 : 5, 0.9%\n",
      "bristol_bristol_person_45 : 18, 3.4%\n",
      "bristol_bristol_person_40 : 27, 5.1%\n",
      "wigan_wigan_person_19 : 9, 1.7%\n",
      "bristol_bristol_person_31 : 4, 0.8%\n",
      "spal_team_a_spal_team_a_person_10 : 3, 0.6%\n",
      "bristol_bristol_person_4 : 13, 2.5%\n",
      "spal_team_a_spal_team_a_person_17 : 5, 0.9%\n",
      "wigan_wigan_person_4 : 2, 0.4%\n",
      "middlesbrough_middlesbrough_person_17 : 5, 0.9%\n",
      "middlesbrough_middlesbrough_person_6 : 18, 3.4%\n",
      "middlesbrough_middlesbrough_person_8 : 15, 2.8%\n",
      "bristol_bristol_person_6 : 13, 2.5%\n",
      "spal_team_b_spal_team_b_person_23 : 3, 0.6%\n",
      "spal_team_a_spal_team_a_person_15 : 5, 0.9%\n",
      "nottingham_forrest_nottingham_forrest_person_19 : 6, 1.1%\n",
      "bristol_bristol_person_5 : 22, 4.2%\n",
      "wigan_wigan_person_3 : 6, 1.1%\n",
      "spal_team_b_spal_team_b_person_37 : 9, 1.7%\n",
      "spal_team_b_spal_team_b_person_10 : 1, 0.2%\n",
      "bristol_bristol_person_14 : 34, 6.4%\n",
      "bristol_bristol_person_11 : 18, 3.4%\n",
      "middlesbrough_middlesbrough_person_26 : 1, 0.2%\n",
      "nottingham_forrest_nottingham_forrest_person_8 : 4, 0.8%\n",
      "wigan_wigan_person_15 : 2, 0.4%\n",
      "bristol_bristol_person_32 : 3, 0.6%\n",
      "middlesbrough_middlesbrough_person_5 : 9, 1.7%\n",
      "middlesbrough_middlesbrough_person_2 : 3, 0.6%\n",
      "bristol_bristol_person_9 : 6, 1.1%\n",
      "wigan_wigan_person_9 : 15, 2.8%\n",
      "nottingham_forrest_nottingham_forrest_person_28 : 9, 1.7%\n",
      "middlesbrough_middlesbrough_person_27 : 8, 1.5%\n",
      "wigan_wigan_person_5 : 15, 2.8%\n",
      "bristol_bristol_person_29 : 11, 2.1%\n",
      "nottingham_forrest_nottingham_forrest_person_11 : 3, 0.6%\n",
      "spal_team_a_spal_team_a_person_77 : 4, 0.8%\n",
      "nottingham_forrest_nottingham_forrest_person_23 : 16, 3.0%\n",
      "middlesbrough_middlesbrough_person_11 : 1, 0.2%\n",
      "wigan_wigan_person_21 : 6, 1.1%\n",
      "wigan_wigan_person_22 : 4, 0.8%\n",
      "bristol_bristol_person_42 : 11, 2.1%\n",
      "\n",
      "\n",
      "Number of instances in each class of TEST dataset:\n",
      "nottingham_forrest_nottingham_forrest_person_7 : 13, 5.0%\n",
      "bristol_bristol_person_25 : 21, 8.0%\n",
      "wigan_wigan_person_20 : 6, 2.3%\n",
      "bristol_bristol_person_19 : 7, 2.7%\n",
      "bristol_bristol_person_23 : 13, 5.0%\n",
      "spal_team_a_spal_team_a_person_19 : 1, 0.4%\n",
      "bristol_bristol_person_8 : 15, 5.7%\n",
      "nottingham_forrest_nottingham_forrest_person_22 : 5, 1.9%\n",
      "nottingham_forrest_nottingham_forrest_person_18 : 1, 0.4%\n",
      "bristol_bristol_person_45 : 7, 2.7%\n",
      "wigan_wigan_person_19 : 8, 3.1%\n",
      "bristol_bristol_person_40 : 13, 5.0%\n",
      "bristol_bristol_person_31 : 4, 1.5%\n",
      "spal_team_a_spal_team_a_person_6 : 1, 0.4%\n",
      "bristol_bristol_person_4 : 8, 3.1%\n",
      "spal_team_b_spal_team_b_person_29 : 1, 0.4%\n",
      "spal_team_a_spal_team_a_person_17 : 4, 1.5%\n",
      "middlesbrough_middlesbrough_person_17 : 2, 0.8%\n",
      "middlesbrough_middlesbrough_person_6 : 11, 4.2%\n",
      "bristol_bristol_person_6 : 9, 3.4%\n",
      "middlesbrough_middlesbrough_person_8 : 8, 3.1%\n",
      "spal_team_a_spal_team_a_person_15 : 4, 1.5%\n",
      "nottingham_forrest_nottingham_forrest_person_19 : 4, 1.5%\n",
      "bristol_bristol_person_5 : 4, 1.5%\n",
      "wigan_wigan_person_3 : 3, 1.1%\n",
      "spal_team_b_spal_team_b_person_37 : 5, 1.9%\n",
      "spal_team_b_spal_team_b_person_10 : 1, 0.4%\n",
      "bristol_bristol_person_14 : 14, 5.3%\n",
      "bristol_bristol_person_11 : 10, 3.8%\n",
      "nottingham_forrest_nottingham_forrest_person_8 : 3, 1.1%\n",
      "bristol_bristol_person_32 : 6, 2.3%\n",
      "middlesbrough_middlesbrough_person_5 : 3, 1.1%\n",
      "middlesbrough_middlesbrough_person_2 : 2, 0.8%\n",
      "wigan_wigan_person_9 : 3, 1.1%\n",
      "nottingham_forrest_nottingham_forrest_person_28 : 4, 1.5%\n",
      "middlesbrough_middlesbrough_person_27 : 7, 2.7%\n",
      "wigan_wigan_person_5 : 4, 1.5%\n",
      "bristol_bristol_person_29 : 7, 2.7%\n",
      "spal_team_a_spal_team_a_person_77 : 3, 1.1%\n",
      "nottingham_forrest_nottingham_forrest_person_23 : 6, 2.3%\n",
      "middlesbrough_middlesbrough_person_11 : 2, 0.8%\n",
      "wigan_wigan_person_21 : 4, 1.5%\n",
      "bristol_bristol_person_42 : 5, 1.9%\n"
     ]
    }
   ],
   "source": [
    "# Print some information\n",
    "# First, number of training, validation and test samples\n",
    "print(\"Number of training samples: \", len(train_idx))\n",
    "print(\"Number of validation samples: \", len(valid_idx))\n",
    "print(\"Number of test samples: \", len(test_idx))\n",
    "\n",
    "# Print the number of instances in each set\n",
    "# Each individual set has a similar proportion to the whole dataset as required\n",
    "print('Number of instances in each class of TRAIN dataset:')\n",
    "print_target_counts(train_targets)\n",
    "print('\\n')\n",
    "print('Number of instances in each class of VALID dataset:')\n",
    "print_target_counts(valid_targets)\n",
    "print('\\n')\n",
    "print('Number of instances in each class of TEST dataset:')\n",
    "print_target_counts(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train, validation and test dataloaders\n",
    "# Train and validation are sampled randomly\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "# test is not sampled randomly so images can be iterated in order for visualisation\n",
    "test_sampler = torch.utils.data.Subset(train_dataset,test_idx)\n",
    "\n",
    "# train and validation have batch size set. test has batch size of 1 to process each image separately\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_sampler, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the correct number of predictions from predictions and labels\n",
    "def get_num_correct(preds, labels):\n",
    "    \n",
    "    corr1 = preds[0].argmax(dim=1).eq(labels[0])\n",
    "    corr2 = preds[1].argmax(dim=1).eq(labels[1])\n",
    "    \n",
    "    corr = torch.logical_and(corr1,corr2)\n",
    "    \n",
    "    return corr.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, total_correct:72, loss: 29389.2, validation_total_correct: 37 validation_loss: 45.9,\n",
      "epoch: 1, total_correct:103, loss: 147.9, validation_total_correct: 37 validation_loss: 45.9,\n",
      "epoch: 2, total_correct:118, loss: 147.1, validation_total_correct: 34 validation_loss: 45.5,\n",
      "epoch: 3, total_correct:110, loss: 146.9, validation_total_correct: 22 validation_loss: 45.7,\n",
      "epoch: 4, total_correct:103, loss: 146.9, validation_total_correct: 34 validation_loss: 45.7,\n",
      "epoch: 5, total_correct:87, loss: 146.8, validation_total_correct: 34 validation_loss: 45.7,\n",
      "epoch: 6, total_correct:119, loss: 146.9, validation_total_correct: 37 validation_loss: 45.5,\n",
      "epoch: 7, total_correct:101, loss: 146.7, validation_total_correct: 37 validation_loss: 45.5,\n",
      "epoch: 8, total_correct:110, loss: 146.9, validation_total_correct: 37 validation_loss: 45.9,\n"
     ]
    }
   ],
   "source": [
    "# initialise model\n",
    "model = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "# iterate over each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # initialise total loss and total_correct variables\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # iterate over batches in training dataset\n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels1, labels2 = batch \n",
    "\n",
    "        preds1, preds2 = model(images) # pass batch to model forward pass\n",
    "        loss1 = F.cross_entropy(preds1, labels1) # calculate Loss\n",
    "        loss2 = F.cross_entropy(preds2, labels2) # calculate Loss\n",
    "        \n",
    "        loss = loss1+loss2\n",
    "        \n",
    "        optimizer.zero_grad() # zero greadients\n",
    "        loss.backward() # calculate Gradients\n",
    "        optimizer.step() # update Weights\n",
    "\n",
    "        total_loss += loss.item() # add loss to total loss\n",
    "        total_correct += get_num_correct([preds1,preds2], [labels1,labels2]) # add prediction to total correct\n",
    "    \n",
    "    # set model to evaluate\n",
    "    model.eval()\n",
    "    \n",
    "    # initialise total loss and total_correct for validation set\n",
    "    val_total_loss = 0\n",
    "    val_total_correct = 0\n",
    "    \n",
    "    # iterate over eatch batch in validation set\n",
    "    for val_batch in valid_loader:\n",
    "        val_images, val_labels1, val_labels2 = val_batch\n",
    "        \n",
    "        val_pred1, val_pred2 = model(val_images) # make predcitions\n",
    "        val_loss1 = F.cross_entropy(val_pred1, val_labels1) # calculate losses\n",
    "        val_loss2 = F.cross_entropy(val_pred2, val_labels2) # calculate losses\n",
    "        \n",
    "        val_loss = val_loss1 + val_loss2\n",
    "        \n",
    "        val_total_loss += val_loss.item() # add to total loss\n",
    "        val_total_correct += get_num_correct([val_pred1,val_pred2],[val_labels1,val_labels2]) # add prediction to total correct\n",
    "    \n",
    "    # print epoch results\n",
    "    print(\n",
    "        'epoch: {},'.format(epoch), \n",
    "        'total_correct:{},'.format(total_correct), \n",
    "        'loss: {:.1f},'.format(total_loss),\n",
    "        'validation_total_correct: {}'.format(val_total_correct),\n",
    "        'validation_loss: {:.1f},'.format(val_total_loss)\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise prediction and target variables for training, validation and test set\n",
    "train_predictions = {'Team':[], 'Person':[]}\n",
    "train_targets = {'Team':[], 'Person':[]}\n",
    "val_predictions = {'Team':[], 'Person':[]}\n",
    "val_targets = {'Team':[], 'Person':[]}\n",
    "test_predictions = {'Team':[], 'Person':[]}\n",
    "test_targets = {'Team':[], 'Person':[]}\n",
    "\n",
    "# also initialise loss and total correct variables for test set\n",
    "test_total_loss = 0\n",
    "test_total_correct = 0\n",
    "train_total_correct = 0\n",
    "val_total_correct = 0\n",
    "\n",
    "# iterate over each training batch\n",
    "for batch in train_loader: # get batch\n",
    "    train_images, train_labels1, train_labels2 = batch \n",
    "    train_preds1, train_preds2 = model(train_images) # get predictions for batch\n",
    "    train_predictions['Team'].extend(train_preds1.argmax(dim=1)) # append predictions for team\n",
    "    train_predictions['Person'].extend(train_preds2.argmax(dim=1)) # append predictions for person\n",
    "    train_targets['Team'].extend(train_labels1) # append team truth\n",
    "    train_targets['Person'].extend(train_labels2) # append person truth\n",
    "  \n",
    "    train_total_correct += get_num_correct([train_preds1,train_preds2], \n",
    "                                           [train_labels1,train_labels2])\n",
    "\n",
    "# iterate over each validation batch\n",
    "for batch in valid_loader: # get batch\n",
    "    val_images, val_labels1, val_labels2 = batch \n",
    "    val_preds1, val_preds2 = model(val_images) # get predictions for batch\n",
    "    val_predictions['Team'].extend(val_preds1.argmax(dim=1)) # append predictions for team\n",
    "    val_predictions['Person'].extend(val_preds2.argmax(dim=1)) # append predictions for person  \n",
    "    val_targets['Team'].extend(val_labels1) # append team truth\n",
    "    val_targets['Person'].extend(val_labels2) # append person truth    \n",
    "    val_total_correct += get_num_correct([val_preds1,val_preds2], \n",
    "                                           [val_labels1,val_labels2])\n",
    "\n",
    "# iterate over each test sample\n",
    "for test_image,test_label1, test_label2 in test_loader: # get sample\n",
    "    test_pred1, test_pred2 = model(test_image) # get prediction\n",
    "    test_predictions['Team'].extend(test_pred1.argmax(dim=1)) # append predictions for team\n",
    "    test_predictions['Person'].extend(test_pred2.argmax(dim=1)) # append predictions for person  \n",
    "    test_targets['Team'].extend(test_label1) # append team truth\n",
    "    test_targets['Person'].extend(test_label2) # append person truth\n",
    "    test_total_correct += get_num_correct([test_pred1,test_pred2], \n",
    "                                           [test_label1,test_label2])   \n",
    "    test_loss1 = F.cross_entropy(test_pred1, test_label1) # calculate loss\n",
    "    test_loss2 = F.cross_entropy(test_pred2, test_label2) # calculate loss\n",
    "    test_total_loss += test_loss1.item()+test_loss2.item() # add loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions and ground truth targets from index to labels\n",
    "train_predictions_labels = {'Team':[], 'Person':[]}\n",
    "train_targets_labels = {'Team':[], 'Person':[]}\n",
    "val_predictions_labels = {'Team':[], 'Person':[]}\n",
    "val_targets_labels = {'Team':[], 'Person':[]}\n",
    "test_predictions_labels = {'Team':[], 'Person':[]}\n",
    "test_targets_labels = {'Team':[], 'Person':[]}\n",
    "\n",
    "# training set\n",
    "train_targets_labels['Team'] = [train_dataset.idx_to_label1[p.item()] for p in train_targets['Team']]\n",
    "train_targets_labels['Person'] = [train_dataset.idx_to_label2[p.item()] for p in train_targets['Person']]\n",
    "train_predictions_labels['Team'] = [train_dataset.idx_to_label1[p.item()] for p in train_predictions['Team']]\n",
    "train_predictions_labels['Person'] = [train_dataset.idx_to_label2[p.item()] for p in train_predictions['Person']]\n",
    "\n",
    "# validation set\n",
    "val_predictions_labels['Team'] = [train_dataset.idx_to_label1[p.item()] for p in val_predictions['Team']]\n",
    "val_predictions_labels['Person'] = [train_dataset.idx_to_label2[p.item()] for p in val_predictions['Person']]\n",
    "val_targets_labels['Team'] = [train_dataset.idx_to_label1[p.item()] for p in val_targets['Team']]\n",
    "val_targets_labels['Person'] = [train_dataset.idx_to_label2[p.item()] for p in val_targets['Person']]\n",
    "\n",
    "# test set\n",
    "test_predictions_labels['Team'] = [train_dataset.idx_to_label1[p.item()] for p in test_predictions['Team']]\n",
    "test_predictions_labels['Person'] = [train_dataset.idx_to_label2[p.item()] for p in test_predictions['Person']]\n",
    "test_targets_labels['Team'] = [train_dataset.idx_to_label1[p.item()] for p in test_targets['Team']]\n",
    "test_targets_labels['Person'] = [train_dataset.idx_to_label2[p.item()] for p in test_targets['Person']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy of training, validation and test set predictions\n",
    "print('Training dataset accuracy: {:.1f}%'.format(100*train_total_correct/len(train_targets_labels['Team'])))\n",
    "print('Validation dataset accuracy: {:.1f}%'.format(100*val_total_correct/len(val_targets_labels['Team'])))\n",
    "print('Test dataset accuracy: {:.1f}%'.format(100*test_total_correct/len(test_targets_labels['Team'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT SOME RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to plot tiles from test set, given list of indices\n",
    "def plot_tiles(idx_to_plot,nrows,ncols,suptitle):\n",
    "    imnum = 1\n",
    "    plt.figure(figsize=(25,13))\n",
    "    for i, [image,label1,label2] in enumerate(test_loader):\n",
    "        if i in idx_to_plot:\n",
    "            plt.subplot(nrows,ncols,imnum)\n",
    "            plt.imshow(image.squeeze().permute(1,2,0))\n",
    "            plt.axis('off')\n",
    "\n",
    "            # get prediction for image\n",
    "            team_pred_idx, person_pred_idx = model(image)\n",
    "            # convert prediction from index to label\n",
    "            team_pred_label = train_dataset.idx_to_label1[team_pred_idx.argmax(dim=1).item()]\n",
    "            person_pred_label = train_dataset.idx_to_label2[person_pred_idx.argmax(dim=1).item()]\n",
    "\n",
    "            team_target_label = train_dataset.idx_to_label1[label1.item()]\n",
    "            person_target_label = train_dataset.idx_to_label2[label2.item()]\n",
    "\n",
    "            # create title for each image with ground truth & prediction\n",
    "            imtitle = ('Team truth: ' + team_target_label + '\\n ' +  \n",
    "                       'Team predict: ' + team_pred_label + '\\n ' +\n",
    "                      'Person truth: ' + person_target_label + '\\n ' +\n",
    "                      'Person predict: ' + person_pred_label)\n",
    "\n",
    "            # plot image\n",
    "            plt.title(imtitle, fontsize=14)\n",
    "\n",
    "            imnum = imnum+1\n",
    "\n",
    "    plt.suptitle(suptitle,fontsize=28)\n",
    "    plt.show()\n",
    "\n",
    "# get index of all correct predictions in the test set\n",
    "index_test_correct = []\n",
    "index_test_incorrect = []\n",
    "for i,t_pred in enumerate(test_predictions_labels['Team']):\n",
    "    if (t_pred == test_targets_labels['Team'][i]) and (test_predictions_labels['Person'][i] == test_targets_labels['Person'][i]):\n",
    "        index_test_correct.append(i)\n",
    "    else:\n",
    "        index_test_incorrect.append(i)\n",
    "\n",
    "# define number of images to plot\n",
    "num_to_plot = 8\n",
    "\n",
    "# get indices from list of correct and incorrect predictions\n",
    "random.seed(42)\n",
    "idx_to_plot_correct = random.sample(index_test_correct,k=num_to_plot)\n",
    "idx_to_plot_incorrect = random.sample(index_test_incorrect,k=num_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some correct predictions\n",
    "plot_tiles(idx_to_plot_correct,nrows=2,ncols=4,suptitle='Correct Predictions')\n",
    "# plot some incorrect predictions\n",
    "plot_tiles(idx_to_plot_incorrect,nrows=2,ncols=4,suptitle='Inorrect Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING MODEL\n",
    "# get example input from test set\n",
    "example_im = torch.zeros(1, 3, 224, 224)\n",
    "\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(model, example_im)\n",
    "\n",
    "# test output\n",
    "output = traced_script_module(example_im)\n",
    "print(output)\n",
    "\n",
    "# save model\n",
    "traced_script_module.save(\"team_and_person_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
